{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'정부': 0, '가': 1, '발표': 2, '하는': 3, '물가상승률': 4, '과': 5, '소비자': 6, '느끼는': 7, '은': 8, '다르다': 9}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 2, 1, 1, 2, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#자연어 처리를 위해서는 문자를 숫자로 수치화하는 것.\n",
    "#국소 표현 방법(이산 표현 방법)은 단어에 번호를 부여하는 것.\n",
    "#분산 표현 방법(연속 표현 방법)은 주변 단어를 참고한다. puppy옆에 cute, lovely가 자주 등장하니까.\n",
    "#국소는 뉘앙스x, 분산은 뉘앙스o\n",
    "#BoW는 국소표현, 단어의 빈도수를 카운트해 수치화하는 단어 표현 방법\n",
    "#LSA는 뉘앙스를 반영하는 연속표현\n",
    "\n",
    "#BoW: 단어의 출현 빈도에만 집중하는 텍스트 데이터의 수치화 표현 방법\n",
    "\n",
    "from konlpy.tag import Okt\n",
    "import re\n",
    "okt=Okt()\n",
    "\n",
    "token=re.sub(\"(\\.)\",\"\",\"정부가 발표하는 물가상승률과 소비자가 느끼는 물가상승률은 다르다.\")\n",
    "#정규 표현식을 통해 온점을 제거하는 정제 작업\n",
    "token=okt.morphs(token)\n",
    "#OKT형태소 분석기를 통해 토큰화 작업을 수행한 뒤에 token에다가 넣습니다. \n",
    "word2index={}\n",
    "bow=[]\n",
    "for voca in token:\n",
    "    if voca not in word2index.keys():\n",
    "        word2index[voca]=len(word2index)\n",
    "        #token을 읽으면서 word2index에 없는 단어는 추가, 이미 있는 단어는 넘긴다.\n",
    "        bow.insert(len(word2index)-1,1)\n",
    "        #bow전체에 전부 기본값 1을 넣어준다. 단어의 개수는 최소 1개 이상이기 때문이다.\n",
    "    else:\n",
    "        index=word2index.get(voca)\n",
    "        #\\재등장하는 단어의 인덱스를 받아온다.\n",
    "        bow[index]=bow[index]+1\n",
    "        #재등장한 단어는 해당하는 인덱스의 위치에 1을 더해준다.(단어의 개수를 센다.)\n",
    "print(word2index)\n",
    "#token을 읽으면서 word2index에 없는 단어는 새로 추가하고 이미 있는 단어는 넘긴다.\n",
    "bow\n",
    "#두번째꺼는 해당 인덱스의 글이 몇번 나오는지 확인시켜준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 2 1 2 1]]\n",
      "{'you': 4, 'know': 1, 'want': 3, 'your': 5, 'love': 2, 'because': 0}\n"
     ]
    }
   ],
   "source": [
    "#CounterVectorizer클래스로 BoW 만들기\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "corpus=['you know I want your love. because I love you.']\n",
    "vector=CountVectorizer()\n",
    "print(vector.fit_transform(corpus).toarray())#코퍼스로부터 각 단어의 빈도수를 기록\n",
    "print(vector.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 1 1]]\n",
      "{'family': 1, 'important': 2, 'thing': 4, 'it': 3, 'everything': 0}\n"
     ]
    }
   ],
   "source": [
    "#불용어를 제거한 BoW만들기\n",
    "#불용어는 자연어처리에서 별로 의미를 갖지 않는단어들\n",
    "#빈도수를 수치화하겠다는 것은 결국 텍스트 내에서 어떤 단어들이 중요한지를 보고싶다.\n",
    "#\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "text=[\"Family is not an important thing. It's everything.\"]\n",
    "vect=CountVectorizer(stop_words=[\"the\",\"a\",\"an\",\"is\",\"not\"])\n",
    "print(vect.fit_transform(text).toarray())\n",
    "print(vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 1]]\n",
      "{'family': 1, 'important': 2, 'thing': 3, 'everything': 0}\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords #nltk에서 지원하는 불용서 사용\n",
    "text=[\"Family is not an important thing. It's everything.\"]\n",
    "sw=stopwords.words(\"english\")\n",
    "vect=CountVectorizer(stop_words=sw)\n",
    "print(vect.fit_transform(text).toarray())\n",
    "print(vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1]]\n",
      "{'family': 0, 'important': 1, 'thing': 2}\n"
     ]
    }
   ],
   "source": [
    "#CountVectorizer에서 제공하는 자체 불용어 사용\n",
    "text=[\"Family is not an important thing. It's everything.\"]\n",
    "vect=CountVectorizer(stop_words=\"english\")\n",
    "print(vect.fit_transform(text).toarray())\n",
    "print(vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>과일이</th>\n",
       "      <th>길고</th>\n",
       "      <th>노란</th>\n",
       "      <th>먹고</th>\n",
       "      <th>바나나</th>\n",
       "      <th>사과</th>\n",
       "      <th>싶은</th>\n",
       "      <th>저는</th>\n",
       "      <th>좋아요</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   과일이  길고  노란  먹고  바나나  사과  싶은  저는  좋아요\n",
       "0    0   0   0   1    0   1   1   0    0\n",
       "1    0   0   0   1    1   0   1   0    0\n",
       "2    0   1   1   0    2   0   0   0    0\n",
       "3    1   0   0   0    0   0   0   1    1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#문서 단어 행렬 : 서로다른문서들의 BoW들을 결합한 표현방법인 문서단어행렬(DTM)표현방법\n",
    "#행과 열을 반대로 선택하면 TDM이라고 부르기도 한다.\n",
    "\n",
    "#TF-IDF : DTM내에 있는 각 단어에 대한 중요도를 계산할 수 있는 가중치\n",
    "#더 많은 정보를 고려하여 문서를 비교할 수 있다. 그러나 성능이 더 뛰어나지는 않다.\n",
    "#TF-IDF=Term Frequency Inverse Document Frequency 단어빈도 역문서빈도)\n",
    "\n",
    "#tf(d,t) : 특정 문서 d에서의 특정단어 t의 등장 횟수\n",
    "#df(t): 특정단어 t가 등장한 문서의 수 \n",
    "#idf(d,t):df(t)에 반비례하는 수 = log(n/1+df(t))\n",
    "#로그를 사용하는 이유는 IDF 값이 기하급수적으로 커지게 되기 때문에 \n",
    "#불용어와 같이 자주 쓰이는 단어들은 비교적 자주 쓰이지 않는 단어들보다 최소 수십배 자주 등장\n",
    "#그래서 log를 사용하는 것.\n",
    "\n",
    "#파이썬으로 TF-IDF 직접 구현하기\n",
    "\n",
    "import pandas as pd #데이터프레임 사용\n",
    "from math import log #IDF 계산을 위해\n",
    "docs=[\n",
    "    '먹고 싶은 사과',\n",
    "    '먹고 싶은 바나나',\n",
    "    '길고 노란 바나나 바나나',\n",
    "    '저는 과일이 좋아요'\n",
    "]\n",
    "vocab=list(set(w for doc in docs for w in doc.split()))\n",
    "vocab.sort()\n",
    "\n",
    "N=len(docs)#총 문서의 수\n",
    "#TF, IDF, TF-IDF값을 구하는 함수 \n",
    "def tf(t,d):\n",
    "    return d.count(t)\n",
    "def idf(t):\n",
    "    df=0\n",
    "    for doc in docs:\n",
    "        df+=t in doc\n",
    "    return log(N/(df+1))\n",
    "\n",
    "def tfidf(t,d):\n",
    "    return tf(t,d)*idf(t)\n",
    "\n",
    "result=[]\n",
    "for i in range(N):\n",
    "    result.append([])\n",
    "    d=docs[i]\n",
    "    for j in range(len(vocab)):\n",
    "        t=vocab[j]\n",
    "        result[-1].append(tf(t,d))\n",
    "tf_=pd.DataFrame(result,columns=vocab)\n",
    "tf_\n",
    "#정상적으로 DTM이 출력되었다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>과일이</th>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>길고</th>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>노란</th>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>먹고</th>\n",
       "      <td>0.287682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>바나나</th>\n",
       "      <td>0.287682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>사과</th>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>싶은</th>\n",
       "      <td>0.287682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>저는</th>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>좋아요</th>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          IDF\n",
       "과일이  0.693147\n",
       "길고   0.693147\n",
       "노란   0.693147\n",
       "먹고   0.287682\n",
       "바나나  0.287682\n",
       "사과   0.693147\n",
       "싶은   0.287682\n",
       "저는   0.693147\n",
       "좋아요  0.693147"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=[]\n",
    "for j in range(len(vocab)):\n",
    "    t=vocab[j]\n",
    "    result.append(idf(t))\n",
    "\n",
    "idf_=pd.DataFrame(result,index=vocab,columns=[\"IDF\"])\n",
    "idf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>과일이</th>\n",
       "      <th>길고</th>\n",
       "      <th>노란</th>\n",
       "      <th>먹고</th>\n",
       "      <th>바나나</th>\n",
       "      <th>사과</th>\n",
       "      <th>싶은</th>\n",
       "      <th>저는</th>\n",
       "      <th>좋아요</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.287682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.287682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.287682</td>\n",
       "      <td>0.287682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.287682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.575364</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        과일이        길고        노란        먹고       바나나        사과        싶은  \\\n",
       "0  0.000000  0.000000  0.000000  0.287682  0.000000  0.693147  0.287682   \n",
       "1  0.000000  0.000000  0.000000  0.287682  0.287682  0.000000  0.287682   \n",
       "2  0.000000  0.693147  0.693147  0.000000  0.575364  0.000000  0.000000   \n",
       "3  0.693147  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "         저는       좋아요  \n",
       "0  0.000000  0.000000  \n",
       "1  0.000000  0.000000  \n",
       "2  0.000000  0.000000  \n",
       "3  0.693147  0.693147  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=[]\n",
    "for i in range(N):\n",
    "    result.append([])\n",
    "    d=docs[i]\n",
    "    for j in range(len(vocab)):\n",
    "        t=vocab[j]\n",
    "        result[-1].append(tfidf(t,d))\n",
    "        \n",
    "tfidf_=pd.DataFrame(result,columns=vocab)\n",
    "tfidf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 1 0 1 0 1 1]\n",
      " [0 0 1 0 0 0 0 1 0]\n",
      " [1 0 0 0 1 0 1 0 0]]\n",
      "{'you': 7, 'know': 1, 'want': 5, 'your': 8, 'love': 3, 'like': 2, 'what': 6, 'should': 4, 'do': 0}\n"
     ]
    }
   ],
   "source": [
    "#사이킷런을 이용한 DTM와 TF-IDF실습\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "corpus=[\n",
    "    'you know I want your love',\n",
    "    'I like you',\n",
    "    'what should I do ',]\n",
    "vector=CountVectorizer()\n",
    "print(vector.fit_transform(corpus).toarray())#코퍼스로부터 각 단어의 빈도수를 기록한다.\n",
    "print(vector.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.46735098 0.         0.46735098 0.         0.46735098\n",
      "  0.         0.35543247 0.46735098]\n",
      " [0.         0.         0.79596054 0.         0.         0.\n",
      "  0.         0.60534851 0.        ]\n",
      " [0.57735027 0.         0.         0.         0.57735027 0.\n",
      "  0.57735027 0.         0.        ]]\n",
      "{'you': 7, 'know': 1, 'want': 5, 'your': 8, 'love': 3, 'like': 2, 'what': 6, 'should': 4, 'do': 0}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "corpus = [\n",
    "    'you know I want your love',\n",
    "    'I like you',\n",
    "    'what should I do ',    \n",
    "]\n",
    "tfidfv=TfidfVectorizer().fit(corpus)\n",
    "print(tfidfv.transform(corpus).toarray())\n",
    "print(tfidfv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
