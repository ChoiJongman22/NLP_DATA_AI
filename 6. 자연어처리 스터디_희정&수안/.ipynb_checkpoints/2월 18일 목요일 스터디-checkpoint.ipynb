{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ratings.txt', <http.client.HTTPMessage at 0x252654676d0>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Word2Vec _ 네이버 영화 리뷰 분석하기\n",
    "\n",
    "#데이터 전처리 과정\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings.txt\", filename=\"ratings.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_table('ratings.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8112052</td>\n",
       "      <td>어릴때보고 지금다시봐도 재밌어요ㅋㅋ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8132799</td>\n",
       "      <td>디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4655635</td>\n",
       "      <td>폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9251303</td>\n",
       "      <td>와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10067386</td>\n",
       "      <td>안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   8112052                                어릴때보고 지금다시봐도 재밌어요ㅋㅋ      1\n",
       "1   8132799  디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...      1\n",
       "2   4655635               폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.      1\n",
       "3   9251303  와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...      1\n",
       "4  10067386                        안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:5] # 상위 5개 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "train_data = train_data.dropna(how = 'any') # Null 값이 존재하는 행 제거\n",
    "print(train_data.isnull().values.any()) # Null 값이 존재하는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199992\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data)) # 리뷰 개수 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규 표현식을 통한 한글 외 문자 제거\n",
    "train_data['document'] = train_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8112052</td>\n",
       "      <td>어릴때보고 지금다시봐도 재밌어요ㅋㅋ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8132799</td>\n",
       "      <td>디자인을 배우는 학생으로 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산업...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4655635</td>\n",
       "      <td>폴리스스토리 시리즈는 부터 뉴까지 버릴께 하나도 없음 최고</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9251303</td>\n",
       "      <td>와 연기가 진짜 개쩔구나 지루할거라고 생각했는데 몰입해서 봤다 그래 이런게 진짜 영화지</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10067386</td>\n",
       "      <td>안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   8112052                                어릴때보고 지금다시봐도 재밌어요ㅋㅋ      1\n",
       "1   8132799  디자인을 배우는 학생으로 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산업...      1\n",
       "2   4655635                   폴리스스토리 시리즈는 부터 뉴까지 버릴께 하나도 없음 최고      1\n",
       "3   9251303   와 연기가 진짜 개쩔구나 지루할거라고 생각했는데 몰입해서 봤다 그래 이런게 진짜 영화지      1\n",
       "4  10067386                         안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화      1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:5] # 상위 5개 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불용어 정의\n",
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#형태소 분석기를 통한 토큰화작업 _ 시간오래걸림\n",
    "okt = Okt()\n",
    "tokenized_data = []\n",
    "for sentence in train_data['document']:\n",
    "    temp_X = okt.morphs(sentence, stem=True) # 토큰화\n",
    "    temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "    tokenized_data.append(temp_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "리뷰의 최대 길이 : 72\n",
      "리뷰의 평균 길이 : 10.716703668146726\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 리뷰 길이 분포 확인\n",
    "print('리뷰의 최대 길이 :',max(len(l) for l in tokenized_data))\n",
    "print('리뷰의 평균 길이 :',sum(map(len, tokenized_data))/len(tokenized_data))\n",
    "plt.hist([len(s) for s in tokenized_data], bins=50)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#네거티브 샘플링: 20뉴스그룹 데이터 전처리하기\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 샘플 수 : 11314\n"
     ]
    }
   ],
   "source": [
    "dataset = fetch_20newsgroups(shuffle=True, random_state=1, remove=('headers', 'footers', 'quotes'))\n",
    "documents = dataset.data\n",
    "print('총 샘플 수 :',len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = pd.DataFrame({'document':documents})\n",
    "# 특수 문자 제거\n",
    "news_df['clean_doc'] = news_df['document'].str.replace(\"[^a-zA-Z]\", \" \")\n",
    "# 길이가 3이하인 단어는 제거 (길이가 짧은 단어 제거)\n",
    "news_df['clean_doc'] = news_df['clean_doc'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))\n",
    "# 전체 단어에 대한 소문자 변환\n",
    "news_df['clean_doc'] = news_df['clean_doc'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.isnull().values.any() #null이 있는지 확인해보자\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.replace(\"\", float(\"NaN\"), inplace=True)\n",
    "news_df.isnull().values.any()\n",
    "#빈 값을 NULL로 변환하고 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 샘플 수 :  10995\n"
     ]
    }
   ],
   "source": [
    "# 제거\n",
    "news_df.dropna(inplace=True)\n",
    "print('총 샘플 수 : ',len(news_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불용어를 제거\n",
    "stop_words = stopwords.words('english')\n",
    "tokenized_doc = news_df['clean_doc'].apply(lambda x: x.split())\n",
    "tokenized_doc = tokenized_doc.apply(lambda x: [item for item in x if item not in stop_words])\n",
    "tokenized_doc = tokenized_doc.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 샘플 수 : 10940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "# 단어가 1개 이하인 샘플의 인덱스를 찾아서 저장하고, 해당 샘플들은 제거.\n",
    "drop_train = [index for index, sentence in enumerate(tokenized_doc) if len(sentence) <= 1]\n",
    "tokenized_doc = np.delete(tokenized_doc, drop_train, axis=0)\n",
    "print('총 샘플 수 :',len(tokenized_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#단어 집합을 생성하고 정수 인코딩을 진행합니다.\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(tokenized_doc)\n",
    "\n",
    "word2idx = tokenizer.word_index\n",
    "idx2word = {v:k for k, v in word2idx.items()}\n",
    "encoded = tokenizer.texts_to_sequences(tokenized_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9, 59, 603, 207, 3278, 1495, 474, 702, 9470, 13686, 5533, 15227, 702, 442, 702, 70, 1148, 1095, 1036, 20294, 984, 705, 4294, 702, 217, 207, 1979, 15228, 13686, 4865, 4520, 87, 1530, 6, 52, 149, 581, 661, 4406, 4988, 4866, 1920, 755, 10668, 1102, 7837, 442, 957, 10669, 634, 51, 228, 2669, 4989, 178, 66, 222, 4521, 6066, 68, 4295], [1026, 532, 2, 60, 98, 582, 107, 800, 23, 79, 4522, 333, 7838, 864, 421, 3825, 458, 6488, 458, 2700, 4730, 333, 23, 9, 4731, 7262, 186, 310, 146, 170, 642, 1260, 107, 33568, 13, 985, 33569, 33570, 9471, 11491]]\n"
     ]
    }
   ],
   "source": [
    "print(encoded[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합의 크기 : 64277\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(word2idx) + 1 \n",
    "print('단어 집합의 크기 :', vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#네거티브 샘플링을 통한 데이터셋 구성하기\n",
    "#시간이 오래걸려서 상위 10개만 해볼게요!\n",
    "from tensorflow.keras.preprocessing.sequence import skipgrams\n",
    "# 네거티브 샘플링\n",
    "skip_grams = [skipgrams(sample, vocabulary_size=vocab_size, window_size=10) for sample in encoded[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(realize (1036), described (984)) -> 1\n",
      "(disagree (1495), world (70)) -> 1\n",
      "(austria (4866), daily (1920)) -> 1\n",
      "(subsidizing (15228), jrnki (30035)) -> 0\n",
      "(least (87), degree (1530)) -> 1\n"
     ]
    }
   ],
   "source": [
    "# 첫번째 샘플인 skip_grams[0] 내 skipgrams로 형성된 데이터셋 확인\n",
    "pairs, labels = skip_grams[0][0], skip_grams[0][1]\n",
    "for i in range(5):\n",
    "    print(\"({:s} ({:d}), {:s} ({:d})) -> {:d}\".format(\n",
    "          idx2word[pairs[i][0]], pairs[i][0], \n",
    "          idx2word[pairs[i][1]], pairs[i][1], \n",
    "          labels[i]))\n",
    "    \n",
    "#중심/주변단어의 관계를 가지면 1, 아니면 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 수 : 10\n"
     ]
    }
   ],
   "source": [
    "print('전체 샘플 수 :',len(skip_grams)) #상위 10개만 했으니까 10이 출력된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2220\n",
      "2220\n"
     ]
    }
   ],
   "source": [
    "# 첫번째 뉴스그룹 샘플에 대해서 생긴 pairs와 labels의 개수\n",
    "print(len(pairs))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_grams = [skipgrams(sample, vocabulary_size=vocab_size, window_size=10) for sample in encoded]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SGNS구현하기\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Embedding, Reshape, Activation, Input\n",
    "from tensorflow.keras.layers import Dot\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from IPython.display import SVG\n",
    "embed_size = 100 #임베딩 벡터의 차원은 100(사용자가 정하는 하이퍼파라미터)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중심 단어를 위한 임베딩 테이블\n",
    "w_inputs = Input(shape=(1, ), dtype='int32')\n",
    "word_embedding = Embedding(vocab_size, embed_size)(w_inputs)\n",
    "\n",
    "# 주변 단어를 위한 임베딩 테이블\n",
    "c_inputs = Input(shape=(1, ), dtype='int32')\n",
    "context_embedding  = Embedding(vocab_size, embed_size)(c_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_product = Dot(axes=2)([word_embedding, context_embedding])\n",
    "dot_product = Reshape((1,), input_shape=(1, 1))(dot_product)\n",
    "output = Activation('sigmoid')(dot_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1, 100)       6427700     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1, 100)       6427700     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot (Dot)                       (None, 1, 1)         0           embedding[0][0]                  \n",
      "                                                                 embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 1)            0           dot[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           reshape[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 12,855,400\n",
      "Trainable params: 12,855,400\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=[w_inputs, c_inputs], outputs=output)\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "plot_model(model, to_file='model3.png', show_shapes=True, show_layer_names=True, rankdir='TB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1 Loss : 4631.826762538403\n",
      "Epoch : 2 Loss : 3674.910331092775\n",
      "Epoch : 3 Loss : 3512.246672101319\n",
      "Epoch : 4 Loss : 3308.578327137977\n",
      "Epoch : 5 Loss : 3083.1352364197373\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 6):\n",
    "    loss = 0\n",
    "    for _, elem in enumerate(skip_grams):\n",
    "        first_elem = np.array(list(zip(*elem[0]))[0], dtype='int32')\n",
    "        second_elem = np.array(list(zip(*elem[0]))[1], dtype='int32')\n",
    "        labels = np.array(elem[1], dtype='int32')\n",
    "        X = [first_elem, second_elem]\n",
    "        Y = labels\n",
    "        loss += model.train_on_batch(X,Y)  \n",
    "    print('Epoch :',epoch, 'Loss :',loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
